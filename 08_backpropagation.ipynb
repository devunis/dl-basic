{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역전파 (Backpropagation)\n",
    "### 연쇄법칙\n",
    "- 기본 수식의 역전파 & 연쇄법칙 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward(x):\n",
    "    y = x ** 2\n",
    "    return y\n",
    "\n",
    "def backward(x):\n",
    "    dy_dx = 2 * x\n",
    "    return dy_dx\n",
    "\n",
    "x = 3.0\n",
    "\n",
    "print(forward(x))\n",
    "print(backward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다층 신경망에서 연쇄법칙 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward(x):\n",
    "    y = x ** 2\n",
    "    z = 2 * y\n",
    "    return z\n",
    "\n",
    "def backward(x):\n",
    "    dy_dx = 2 * x\n",
    "    dz_dy = 2\n",
    "    dz_dx = dz_dy * dy_dx\n",
    "    return dz_dx\n",
    "\n",
    "x = 3.0\n",
    "\n",
    "print(forward(x))\n",
    "print(backward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 활용\n",
    "- 단순 신경망 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22846489 0.42846489]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_d(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "X = np.array([.5, .8])\n",
    "y = np.array([1])\n",
    "\n",
    "W = np.array([.2, .4])\n",
    "\n",
    "# 순전파\n",
    "z = W.dot(X)\n",
    "r = sigmoid(z) # 활성화 함수 통과\n",
    "\n",
    "# 오차 계산\n",
    "loss = .5 * (y - r) ** 2 # MSE\n",
    "\n",
    "# 역전파 (기울기 계산)\n",
    "d = (r - y) * sigmoid_d(z)\n",
    "grad_w = d * x\n",
    "\n",
    "# 가중치 갱신\n",
    "W -= 0.1 * grad_w # 학습률 0.1\n",
    "\n",
    "print(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5007592]\n",
      " [0.6007154]]\n",
      "[[0.200365  0.400584 ]\n",
      " [0.100438  0.3007008]]\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_d(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "X = np.array([.5, .8])\n",
    "y = np.array([1])\n",
    "\n",
    "W1 = np.array([[.2, .4], [.1, .3]])\n",
    "b1 = np.array([.1, .2])\n",
    "W2 = np.array([[.5], [.6]])\n",
    "b2 = np.array([.3])\n",
    "\n",
    "# 순전파\n",
    "z1 = W1.dot(X) + b1\n",
    "r1 = relu(z1) # 활성화 함수 통과\n",
    "\n",
    "z2 = r1.dot(W2) + b2\n",
    "r2 = relu(z2) # 활성화 함수 통과\n",
    "\n",
    "# 오차 계산\n",
    "loss = .5 * (y - r) ** 2 # MSE\n",
    "\n",
    "# 역전파 (기울기 계산)\n",
    "d2 = (r2 - 1) * relu_d(z2)\n",
    "grad_W2 = np.outer(r1, d2)\n",
    "d1 = W2.dot(d2) * relu_d(z1)\n",
    "grad_W1 = np.outer(d1, X)\n",
    "\n",
    "# 가중치 갱신\n",
    "learning_rate = .01\n",
    "W2 -= learning_rate * grad_W2\n",
    "W1 -= learning_rate * grad_W1\n",
    "\n",
    "print(W2)\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치미분과 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000000000039306\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "def num_d_gradient(f, x):\n",
    "    h = 1e-5\n",
    "    return (f(x + h) - f(x - h)) / (2 * h) # central difference\n",
    "\n",
    "def backward_gradient(x):\n",
    "    return 2 * x\n",
    "\n",
    "print(num_d_gradient(f, 3.0))\n",
    "print(backward_gradient(3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 숫자 맞추기 AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: 17.037962347336638, loss: 384.6316813413478\n",
      "epoch 10: 27.26016638647881, loss: 134.11277466314144\n",
      "epoch 15: 33.29627564955187, loss: 46.76223306702692\n",
      "epoch 20: 36.86053780830388, loss: 16.30498248140361\n",
      "epoch 25: 38.965198970425355, loss: 5.685195857473662\n",
      "epoch 30: 40.20798034004646, loss: 1.9823052232469052\n",
      "epoch 35: 40.941830310994035, loss: 0.691187093043812\n",
      "epoch 40: 41.37516138033887, loss: 0.24100203741977202\n",
      "epoch 45: 41.6310390434763, loss: 0.08403221446844601\n",
      "epoch 50: 41.78213224478232, loss: 0.029300221459007722\n",
      "epoch 55: 41.871351269221506, loss: 0.010216355512911739\n",
      "epoch 60: 41.92403421096261, loss: 0.0035622229037491297\n",
      "epoch 65: 41.95514296123131, loss: 0.0012420703253677495\n",
      "epoch 70: 41.97351236717747, loss: 0.0004330831435438802\n",
      "epoch 75: 41.984359317694626, loss: 0.0001510067549244059\n",
      "epoch 80: 41.9907643335055, loss: 5.265279975158397e-05\n",
      "epoch 85: 41.99454643129167, loss: 1.8358896084288808e-05\n",
      "epoch 90: 41.99677972221341, loss: 6.401351248635689e-06\n",
      "epoch 95: 41.99809845816979, loss: 2.2320131679107747e-06\n",
      "epoch 100: 41.99887715856468, loss: 7.782548696715033e-07\n",
      "epoch 105: 41.99933697336087, loss: 2.71360693951474e-07\n",
      "epoch 110: 41.999608489399854, loss: 9.461762347245234e-08\n",
      "epoch 115: 41.99976881690573, loss: 3.2991125356982834e-08\n",
      "epoch 120: 41.999863488694665, loss: 1.1503294126622537e-08\n",
      "epoch 125: 41.99991939143931, loss: 4.010950651568703e-09\n",
      "epoch 130: 41.999952401451, loss: 1.3985320166007526e-09\n",
      "epoch 135: 41.9999718935328, loss: 4.876379620720853e-10\n",
      "epoch 140: 41.99998340341219, loss: 1.7002884391109482e-10\n",
      "epoch 145: 41.99999019988086, loss: 5.928539201737457e-11\n",
      "epoch 150: 41.99999421312765, loss: 2.0671538028228056e-11\n",
      "epoch 155: 41.999996582909745, loss: 7.207719652128026e-12\n",
      "epoch 160: 41.99999798224238, loss: 2.5131764322691513e-12\n",
      "epoch 165: 41.9999988085343, loss: 8.762904369447578e-13\n",
      "epoch 170: 41.99999929645142, loss: 3.055435824497586e-13\n",
      "epoch 175: 41.9999995845616, loss: 1.0653645798594509e-13\n",
      "epoch 180: 41.99999975468778, loss: 3.7146967717179546e-14\n",
      "epoch 185: 41.99999985514559, loss: 1.2952346322308578e-14\n",
      "epoch 190: 41.99999991446492, loss: 4.5162036294101526e-15\n",
      "epoch 195: 41.99999994949239, loss: 1.5747029371506111e-15\n",
      "epoch 200: 41.99999997017576, loss: 5.4906519632687365e-16\n",
      "epoch 205: 41.99999998238909, loss: 1.9144703136263112e-16\n",
      "epoch 210: 41.99999998960093, loss: 6.675345603881456e-17\n",
      "epoch 215: 41.99999999385946, loss: 2.3275458177210547e-17\n",
      "epoch 220: 41.99999999637407, loss: 8.115637819017143e-18\n",
      "epoch 225: 41.99999999785892, loss: 2.82976159394881e-18\n",
      "epoch 230: 41.99999999873572, loss: 9.866713947067217e-19\n",
      "epoch 235: 41.999999999253454, loss: 3.4403072464406365e-19\n",
      "epoch 240: 41.999999999559165, loss: 1.1995820865199134e-19\n",
      "epoch 245: 41.99999999973969, loss: 4.1828016286549004e-20\n",
      "epoch 250: 41.99999999984629, loss: 1.4585151306417746e-20\n",
      "epoch 255: 41.99999999990923, loss: 5.085808621744248e-21\n",
      "epoch 260: 41.9999999999464, loss: 1.7735593448188496e-21\n",
      "epoch 265: 41.999999999968345, loss: 6.185300585656909e-22\n",
      "epoch 270: 41.999999999981306, loss: 2.1567909008268973e-22\n",
      "epoch 275: 41.999999999988965, loss: 7.520245088263011e-23\n",
      "epoch 280: 41.999999999993484, loss: 2.621191674899824e-23\n",
      "epoch 285: 41.999999999996156, loss: 9.11799513045551e-24\n",
      "epoch 290: 41.999999999997726, loss: 3.1813182585752964e-24\n",
      "epoch 295: 41.99999999999866, loss: 1.1132405094478919e-24\n",
      "epoch 300: 41.999999999999204, loss: 3.881448089177049e-25\n",
      "epoch 305: 41.999999999999524, loss: 1.3823367414368834e-25\n",
      "epoch 310: 41.999999999999716, loss: 4.8871510800252123e-26\n",
      "epoch 315: 41.99999999999984, loss: 1.7064639101740927e-26\n",
      "epoch 320: 41.9999999999999, loss: 5.679798517591285e-27\n",
      "epoch 325: 41.999999999999936, loss: 2.5243548967072378e-27\n",
      "epoch 330: 41.99999999999997, loss: 6.310887241768094e-28\n",
      "epoch 335: 41.99999999999997, loss: 4.0389678347315804e-28\n",
      "epoch 340: 41.99999999999997, loss: 4.0389678347315804e-28\n",
      "epoch 345: 41.99999999999997, loss: 4.0389678347315804e-28\n",
      "epoch 350: 41.99999999999997, loss: 4.0389678347315804e-28\n",
      "final guess: 41.99999999999997\n"
     ]
    }
   ],
   "source": [
    "target_number = 42\n",
    "\n",
    "guess = np.random.randn()\n",
    "\n",
    "learning_rate = .1\n",
    "\n",
    "for i in range(350):\n",
    "    # 오차 계산\n",
    "    loss = 0.5 * (target_number - guess) ** 2\n",
    "    \n",
    "    # 역전파 (기울기 계산)\n",
    "    grad = (guess - target_number)\n",
    "    \n",
    "    # 업데이트 (guess 업데이트)\n",
    "    guess -= learning_rate * grad\n",
    "    \n",
    "    # epoch 5마다 예측값과 손실 출력\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f'epoch {i+1}: {guess}, loss: {loss}')\n",
    "        \n",
    "print(f'final guess: {guess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "arr.sort"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
